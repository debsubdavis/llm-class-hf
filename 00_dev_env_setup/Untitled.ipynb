{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "703b1ac1-5f17-4cde-a699-26efa30a6c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (3.6.0)\n",
      "Requirement already satisfied: evaluate in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: transformers[sentencepiece] in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (4.52.3)\n",
      "Requirement already satisfied: filelock in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from datasets) (0.32.2)\n",
      "Requirement already satisfied: packaging in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from transformers[sentencepiece]) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from transformers[sentencepiece]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from transformers[sentencepiece]) (0.5.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from transformers[sentencepiece]) (0.2.0)\n",
      "Collecting protobuf (from transformers[sentencepiece])\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/debbiesubocz/anaconda3/envs/llm_hf/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl (425 kB)\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-6.31.1\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets evaluate 'transformers[sentencepiece]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4af125d-90ba-46c3-aee7-e9e2e648cdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'get_default_device'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m classifier = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentiment-analysis\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm_hf/lib/python3.11/site-packages/transformers/pipelines/__init__.py:942\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    941\u001b[39m     model_classes = {\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     framework, model = \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    952\u001b[39m model_config = model.config\n\u001b[32m    953\u001b[39m hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = model.config._commit_hash\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm_hf/lib/python3.11/site-packages/transformers/pipelines/base.py:292\u001b[39m, in \u001b[36minfer_framework_load_model\u001b[39m\u001b[34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m     logger.warning(\n\u001b[32m    287\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    288\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrying to load the model with Tensorflow.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    289\u001b[39m     )\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     model = \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33meval\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    294\u001b[39m         model = model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm_hf/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm_hf/lib/python3.11/site-packages/transformers/modeling_utils.py:309\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    311\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm_hf/lib/python3.11/site-packages/transformers/modeling_utils.py:4252\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4250\u001b[39m \u001b[38;5;66;03m# Potentially detect context manager or global device, and use it (only if no device_map was provided)\u001b[39;00m\n\u001b[32m   4251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_deepspeed_zero3_enabled():\n\u001b[32m-> \u001b[39m\u001b[32m4252\u001b[39m     device_in_context = \u001b[43mget_torch_context_manager_or_global_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4253\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device_in_context == torch.device(\u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   4254\u001b[39m         \u001b[38;5;66;03m# TODO Cyril: raise an error instead of the warning in v4.53 (and change the test to check for raise instead of success)\u001b[39;00m\n\u001b[32m   4255\u001b[39m         logger.warning(\n\u001b[32m   4256\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mWe detected that you are using `from_pretrained` with a meta device context manager or `torch.set_default_device(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   4257\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThis is an anti-pattern and will raise an Error in version v4.53\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIf you want to initialize a model on the meta device, use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4258\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mthe context manager or global device with `from_config`, or `ModelClass(config)`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4259\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm_hf/lib/python3.11/site-packages/transformers/modeling_utils.py:322\u001b[39m, in \u001b[36mget_torch_context_manager_or_global_device\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[33;03mTest if a device context manager is currently in use, or if it is not the case, check if the default device\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[33;03mis not \"cpu\". This is used to infer the correct device to load the model on, in case `device_map` is not provided.\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    321\u001b[39m device_in_context = torch.tensor([]).device\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m default_device = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_default_device\u001b[49m()\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# This case means no context manager was used -> we still check if the default that was potentially set is not cpu\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device_in_context == default_device:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm_hf/lib/python3.11/site-packages/torch/__init__.py:1938\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m   1935\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m   1936\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[34m__name__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1938\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch' has no attribute 'get_default_device'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b6d75-3f5b-4cd5-bf45-3078ac845289",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
